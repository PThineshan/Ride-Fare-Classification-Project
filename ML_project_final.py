# -*- coding: utf-8 -*-
"""Copy of Thinesh_max.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WL01zJ7ACslbJGFdRRJz2kdacjhe7J-8
"""

import numpy as np
import pandas as pd

train_data = pd.read_csv("train.csv", index_col="tripid")
test_features_df = pd.read_csv("test.csv", index_col="tripid")

train_data=train_data.dropna(how='any',axis=0)

# check label counts
train_data.label.value_counts()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
fig, ax = plt.subplots(1, 1, sharex=True)

n_obs = train_data.label.shape[0]

(train_data['label']
    .value_counts()
    .div(n_obs)
    .plot.barh(title="Proportion of tripfare")
)
ax.set_ylabel("label")
fig.tight_layout()

# # separate minority and majority classes
# incorrect = train_data[train_data.label=="incorrect"]
# correct = train_data[train_data.label=="correct"]

# from sklearn.utils import resample
# # upsample minority
# incorrect_upsampled = resample(incorrect,
#                           replace=True, # sample with replacement
#                           n_samples=len(correct), # match number in majority class
#                           random_state=27) # reproducible results

# # combine majority and upsampled minority
# upsampled_train_data = pd.concat([correct, incorrect_upsampled])

# # check new class counts
# upsampled_train_data.label.value_counts()

features_df = train_data.iloc[:, :12]
labels_df = train_data.iloc[:, 12:]
# features_df = upsampled_train_data.iloc[:, :12]
# labels_df = upsampled_train_data.iloc[:, 12:]
# Separate input features and target
# labels_df = train_data.label
# features_df = train_data.drop('label', axis=1)

np.testing.assert_array_equal(features_df.index.values, labels_df.index.values)

features_df.shape, labels_df.shape

features_df['pickup_time'] = features_df['pickup_time'].astype('datetime64')
test_features_df['pickup_time'] = test_features_df['pickup_time'].astype('datetime64')
features_df['drop_time'] = features_df['drop_time'].astype('datetime64')
test_features_df['drop_time'] = test_features_df['drop_time'].astype('datetime64')

import datetime
features_df['pick_up_day'] = features_df['pickup_time'].dt.dayofweek
features_df['drop_day'] = features_df['drop_time'].dt.dayofweek
test_features_df['pick_up_day'] = test_features_df['pickup_time'].dt.dayofweek
test_features_df['drop_day'] = test_features_df['drop_time'].dt.dayofweek

import datetime
features_df['pick_up_hour'] = features_df['pickup_time'].dt.hour
test_features_df['pick_up_hour'] = test_features_df['pickup_time'].dt.hour

features_df.head()

def distance(df):
  from math import sin, cos, sqrt, atan2, radians
  for index, row in df.iterrows():
    
    # approximate radius of earth in km
    R = 6373.0

    lat1 = radians(row['pick_lat'])
    lon1 = radians(row['pick_lon'])
    lat2 = radians(row['drop_lat'])
    lon2 = radians(row['drop_lon'])
  
    dlon = lon2 - lon1
    dlat = lat2 - lat1

    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))

    distance = R * c
    
    df.loc[index, 'distance'] = distance

features_df['distance']=''
test_features_df['distance']=''

distance(features_df)
distance(test_features_df)

features_df['distance'] = features_df['distance'].astype(float)
test_features_df['distance'] = test_features_df['distance'].astype(float)
features_df.head()

def travelling_time(df):
  for index, row in df.iterrows():
    travel_time = row['duration'] - row['meter_waiting']
    df.loc[index, 'travel_time'] = travel_time

features_df['travel_time']=''
test_features_df['travel_time']=''

travelling_time(features_df)
travelling_time(test_features_df)

features_df['travel_time'] = features_df['travel_time'].astype(int)
test_features_df['travel_time'] = test_features_df['travel_time'].astype(int)
features_df.head()

def travel_fare(df):
  for index, row in df.iterrows():
    travel_fare = row['fare'] - row['additional_fare'] - row['meter_waiting_fare'] 
    df.loc[index, 'travel_fare'] = travel_fare

features_df['travel_fare']=''
test_features_df['travel_fare']=''

travel_fare(features_df)
travel_fare(test_features_df)

features_df['travel_fare'] = round(features_df['travel_fare'].astype(float), 2)
test_features_df['travel_fare'] = round(test_features_df['travel_fare'].astype(float), 2)
features_df.head()

features_df=features_df.drop(['pickup_time'], axis=1)
features_df=features_df.drop(['drop_time'], axis=1)
test_features_df=test_features_df.drop(['pickup_time'], axis=1)
test_features_df=test_features_df.drop(['drop_time'], axis=1)

col = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'pick_lat',
'pick_lon', 'drop_lat', 'drop_lon', 'fare', 'pick_up_day', 'distance', 'travel_time', 'pick_up_hour', 'drop_day', 'travel_fare'] 

features_df=features_df[col] 
test_features_df=test_features_df[col]

features_df.head()

test_features_df.head()

labels_df.head()

# #Label Encoding for object to numeric conversion
# from sklearn.preprocessing import LabelEncoder
# le = LabelEncoder()

# labels_df["label"] = le.fit_transform(labels_df["label"].astype(str))
def tran_label_to_num(df):
    if df['label'] == 'correct':
        return 1
    elif df['label'] == 'incorrect':
        return 0
# create sex_new 
labels_df['label']=labels_df.apply(tran_label_to_num,axis=1)
labels_df.head()

from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer

from sklearn.linear_model import LogisticRegression
from sklearn.multioutput import MultiOutputClassifier

from sklearn.pipeline import Pipeline

from sklearn.model_selection import train_test_split

from sklearn.metrics import roc_curve, roc_auc_score

RANDOM_SEED = 6    # Set a random seed for reproducibility!

numeric_cols = features_df.columns[features_df.dtypes != "object"].values
print(numeric_cols)
print(numeric_cols.size)

# chain preprocessing into a Pipeline object
# each step is a tuple of (name you chose, sklearn transformer)
numeric_preprocessing_steps = Pipeline([
    ('standard_scaler', StandardScaler()),
    ('simple_imputer', SimpleImputer(strategy='median'))
])

# create the preprocessor stage of final pipeline
# each entry in the transformer list is a tuple of
# (name you choose, sklearn transformer, list of columns)
preprocessor = ColumnTransformer(
    transformers = [
        ("numeric", numeric_preprocessing_steps, numeric_cols)
    ],
    remainder = "drop"
)

from xgboost import XGBClassifier
estimators = MultiOutputClassifier(
    estimator=XGBClassifier(learning_rate =0.01,
 n_estimators=3000,
 max_depth=4,
 min_child_weight=6,
 gamma=0,
 subsample=0.8,
 colsample_bytree=0.8,
 reg_alpha=0.005,
 objective= 'binary:logistic',
 nthread=4,
 scale_pos_weight=1,
 seed=27)
)

X_train, X_eval, y_train, y_eval = train_test_split(
    features_df,
    labels_df,
    test_size=0.33,
    shuffle=True,
    stratify=labels_df,
    random_state=RANDOM_SEED
)

X_train.shape,y_train.shape

# Commented out IPython magic to ensure Python compatibility.
# %%time
# full_pipeline = Pipeline([
#     ("preprocessor", preprocessor),
#     ("estimators", estimators),
# ])
# # Train model
# full_pipeline.fit(X_train, y_train)

y_pred = full_pipeline.predict(X_eval)
y_pred

from sklearn.metrics import accuracy_score
 accuracy_score(y_eval, y_pred)
 # 0.95375 n_estimators=5000
 # 0.9539285714285715 n_estimators=5000
 # 0.9548214285714286 n_estimators=3000

from sklearn.metrics import f1_score
f1_score(y_eval, y_pred, average='macro')
# 0.8349567404365886
# 0.8364775489378964
# 0.8387801364110306

# Commented out IPython magic to ensure Python compatibility.
# %%time
# full_pipeline = Pipeline([
#     ("preprocessor", preprocessor),
#     ("estimators", estimators),
# ])
# # Train model
# full_pipeline.fit(features_df, labels_df)

test_probas = full_pipeline.predict(test_features_df)
test_probas

submission_df = pd.read_csv("sample_submission.csv", 
                            index_col="tripid")

# Make sure we have the rows in the same order
np.testing.assert_array_equal(test_features_df.index.values, 
                              submission_df.index.values)

# Save predictions to submission data frame
submission_df["prediction"] = test_probas[:, 0]


submission_df

submission_df.to_csv('ML_submission.csv', index=True)

!head ML_submission.csv